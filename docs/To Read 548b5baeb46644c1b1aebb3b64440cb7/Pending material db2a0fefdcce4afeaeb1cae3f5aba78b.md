# Pending material

---

# Long

- [Neural Architectures for Named Entity Recognition](https://arxiv.org/abs/1603.01360)(2016)
- [Representation Learning for Information Extraction from Form-like Documents](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/59f3bb33216eae711b36f3d8b3ee3cc67058803f.pdf)(2020)
- [AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE](https://arxiv.org/abs/2010.11929) (2021)
- DETR : [https://arxiv.org/abs/2005.12872](https://arxiv.org/abs/2005.12872) (2020)
- Machine learning type - Online learning - [https://arxiv.org/abs/1802.02871](https://arxiv.org/abs/1802.02871) (2018)
- Paper to explain gradient descent, optimizer [https://arxiv.org/pdf/1609.04747.pdf](https://arxiv.org/pdf/1609.04747.pdf)  (2017)
- Mercari MLOps - [https://youtu.be/3fo5YyRqRII?t=570](https://youtu.be/3fo5YyRqRII?t=570)
- Minecraft VPT training - [https://arxiv.org/abs/2206.11795](https://arxiv.org/abs/2206.11795) (2022)
- Check what topic of statistic need to be studied
    - from Chou : 初等統計學 抽樣調查 迴歸分析
- ViTDet - [https://arxiv.org/abs/2203.16527](https://arxiv.org/abs/2203.16527) (2022)
    - [https://github.com/facebookresearch/detectron2/tree/main/projects/ViTDet](https://github.com/facebookresearch/detectron2/tree/main/projects/ViTDet)
    

## Short

- sklearn - *stratify -* [https://scikit-learn.org/stable/modules/cross_validation.html#stratification](https://scikit-learn.org/stable/modules/cross_validation.html#stratification)
- Model architecture
    - CNN, Rnn, GAN
- ViT (vision transformer)
- Line OCR source code
    - [https://github.com/clovaai/donut](https://github.com/clovaai/donut)
- Diff - normalize vs standardize vs regularization
    - Regularization
        - Regularization is a way to avoid model from overfitting. It has different kind of techniques, such as L2, dropout…etc
        [https://www.reddit.com/r/learnmachinelearning/comments/w7yrog/what_regularization_does_to_a_machine_learning/?utm_medium=android_app&utm_source=share](https://www.reddit.com/r/learnmachinelearning/comments/w7yrog/what_regularization_does_to_a_machine_learning/?utm_medium=android_app&utm_source=share)
- adversarial validation
- A guy got 2nd on kaggle competition - step by step guide - [https://twitter.com/marktenenholtz/status/1539578965920083968](https://twitter.com/marktenenholtz/status/1539578965920083968)
- MLFlows ← check how to use it
- wandb ← check this
- weak supervision learning ?
- inductive learning
    - refers to a learning algorithm that learns from labeled training data and generalizes to new data, such as a test dataset.
- transductive learning
    - refers to learning from labeled training data and generalizing to available unlabeled (training) data.
    - [https://machinelearningmastery.com/transduction-in-machine-learning/](https://machinelearningmastery.com/transduction-in-machine-learning/)
- MeanShift
    - the 2nd section here - [https://www.christopherlovell.co.uk/blog/2016/07/04/image-pca-deckchair.html](https://www.christopherlovell.co.uk/blog/2016/07/04/image-pca-deckchair.html)
- Semi supervised learning example on mincraft game - [https://openai.com/blog/vpt/](https://openai.com/blog/vpt/)
    - Check its github src - [https://github.com/openai/Video-Pre-Training](https://github.com/openai/Video-Pre-Training)
    - Video pretraining (vpt)
    - Inverse dynamics model (idm)
- Non maximum suppression ( CV)
- Gpu puzzle - an interactive notebook to learn gpu programming - [https://github.com/srush/GPU-Puzzles](https://github.com/srush/GPU-Puzzles)